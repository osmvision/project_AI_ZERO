# üöÄ Projet : Assistant RAG Vocal avec IA Locale

Ce projet est une application web compl√®te (FastAPI + HTML/JS) qui permet √† un utilisateur de poser des questions vocalement √† une base de documents.

L'ensemble du pipeline (S2T, Embedding, LLM) tourne localement.

## Fonctionnalit√©s

* **Frontend :** Interface de chat en HTML/JS pur.
* **API :** Serveur FastAPI (Python).
* **S2T (Voix->Texte) :** `openai-whisper` (tourne localement).
* **RAG (IA) :** `LlamaIndex` utilisant des mod√®les locaux.
* **Mod√®le d'Embedding :** `HuggingFace (BAAI/bge-small-en-v1.5)`.
* **LLM (Cerveau) :** `Ollama (llama3)`.

## üõ†Ô∏è Installation et Lancement

1.  **Pr√©requis :**
    * Installer Python 3.11 (64-bit).
    * Installer [Ollama](https://ollama.com/) et le laisser tourner en fond.

2.  **T√©l√©charger le mod√®le LLM :**
    ```bash
    ollama pull llama3
    ```

3.  **Cloner le d√©p√¥t et installer les d√©pendances :**
    ```bash
    git clone [VOTRE_URL_GITHUB]
    cd zeroAI
    python -m venv .venv
    .\.venv\Scripts\Activate.ps1
    pip install -r requirements.txt
    ```

4.  **Ajouter les documents :**
    * Placez vos fichiers `.txt` ou `.pdf` dans le dossier `/data`.

5.  **Lancer le serveur :**
    ```bash
    uvicorn src.main:app --reload
    ```

6.  **Acc√©der √† l'application :**
    * Ouvrez `http://127.0.0.1:8000/` dans votre navigateur.


